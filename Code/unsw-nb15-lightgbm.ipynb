{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/unsw-nb15-eda/features.csv\n",
      "/kaggle/input/unsw-nb15-eda/test.csv\n",
      "/kaggle/input/unsw-nb15-eda/train.csv\n",
      "/kaggle/input/unsw-nb15/UNSW-NB15_1.csv\n",
      "/kaggle/input/unsw-nb15/UNSW_NB15_testing-set.csv\n",
      "/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv\n",
      "/kaggle/input/unsw-nb15/UNSW-NB15_4.csv\n",
      "/kaggle/input/unsw-nb15/UNSW-NB15_2.csv\n",
      "/kaggle/input/unsw-nb15/UNSW-NB15_LIST_EVENTS.csv\n",
      "/kaggle/input/unsw-nb15/NUSW-NB15_features.csv\n",
      "/kaggle/input/unsw-nb15/UNSW-NB15_3.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        if 'csv' in filename:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "* [The UNSW-NB15 dataset description](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/)\n",
    "* [Feature visualization and preprocessing](https://www.kaggle.com/khairulislam/unsw-nb15-eda)\n",
    "* [Feature importance using RandomForest classifier](https://www.kaggle.com/khairulislam/unsw-nb15-feature-importance)\n",
    "* [Performance with other classifiers](https://www.kaggle.com/khairulislam/unsw-nb15-anomaly-detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def input_train_test():\n",
    "    root = '../input/unsw-nb15/'\n",
    "    train = pd.read_csv(root+'UNSW_NB15_training-set.csv')\n",
    "    test = pd.read_csv(root+'UNSW_NB15_testing-set.csv')\n",
    "    \n",
    "    if train.shape[0] == 82332:\n",
    "        print(\"Train and test sets are reversed here. Fixing them.\")\n",
    "        train, test = test, train\n",
    "    drop_columns = ['attack_cat', 'id']\n",
    "    for df in [train, test]:\n",
    "        for col in drop_columns:\n",
    "            if col in df.columns:\n",
    "                print('Dropping '+col)\n",
    "                df.drop([col], axis=1, inplace=True)\n",
    "    return train, test\n",
    "\n",
    "def get_cat_columns(train):\n",
    "    categorical = []\n",
    "    for col in train.columns:\n",
    "        if train[col].dtype == 'object':\n",
    "            categorical.append(col)\n",
    "    return categorical\n",
    "    \n",
    "def label_encode(train, test):\n",
    "    for col in get_cat_columns(train):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))\n",
    "    return train, test\n",
    "\n",
    "def feature_process(df):\n",
    "    df.loc[~df['state'].isin(['FIN', 'INT', 'CON', 'REQ', 'RST']), 'state'] = 'others'\n",
    "    df.loc[~df['service'].isin(['-', 'dns', 'http', 'smtp', 'ftp-data', 'ftp', 'ssh', 'pop3']), 'service'] = 'others'\n",
    "    df.loc[df['proto'].isin(['igmp', 'icmp', 'rtp']), 'proto'] = 'igmp_icmp_rtp'\n",
    "    df.loc[~df['proto'].isin(['tcp', 'udp', 'arp', 'ospf', 'igmp_icmp_rtp']), 'proto'] = 'others'\n",
    "    return df\n",
    "\n",
    "def get_train_test(train, test, feature_engineer=True, label_encoding=False, scaler=None):\n",
    "    x_train, y_train = train.drop(['label'], axis=1), train['label']\n",
    "    x_test, y_test = test.drop(['label'], axis=1), test['label']\n",
    "    \n",
    "    x_train, x_test = feature_process(x_train), feature_process(x_test)\n",
    "    if scaler is not None:\n",
    "        categorical_columns = get_cat_columns(x_train)\n",
    "        non_categorical_columns = [x for x in x_train.columns if x not in categorical_columns]\n",
    "        x_train[non_categorical_columns] = scaler.fit_transform(x_train[non_categorical_columns])\n",
    "        x_test[non_categorical_columns] = scaler.transform(x_test[non_categorical_columns])\n",
    "    \n",
    "    if label_encoding:\n",
    "        x_train, x_test = label_encode(x_train, x_test)\n",
    "        features = x_train.columns\n",
    "    else:\n",
    "        x_train = pd.get_dummies(x_train)\n",
    "        x_test = pd.get_dummies(x_test)\n",
    "        print(\"Column mismatch {0}, {1}\".format(set(x_train.columns)- set(x_test.columns),  set(x_test.columns)- set(x_train.columns)))\n",
    "        features = list(set(x_train.columns) & set(x_test.columns))\n",
    "    print(f\"Number of features {len(features)}\")\n",
    "    x_train = x_train[features]\n",
    "    x_test = x_test[features]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def run_lgb(x, y, tr_idx, val_idx, param, num_round=100):\n",
    "    lgb_train = lgb.Dataset(x.iloc[tr_idx], y.iloc[tr_idx])\n",
    "    x_val, y_val = x.iloc[val_idx], y.iloc[val_idx]\n",
    "    validation = lgb.Dataset(x_val, y_val)\n",
    "    clf = lgb.train(param, lgb_train, num_round, valid_sets=[validation], early_stopping_rounds=50, verbose_eval=200, feval=lgb_f1_score)\n",
    "    return clf\n",
    "\n",
    "def false_alarm_rate(y_true, y_pred):\n",
    "    CM = metrics.confusion_matrix(y_true, y_pred)\n",
    "    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n",
    "    return (FP+FN)/(TP+TN+FP+FN)\n",
    "\n",
    "def results(y_test, y_prob):\n",
    "    threshold = 0.5\n",
    "    y_pred = np.where(y_prob >= threshold, 1, 0)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    pre = metrics.precision_score(y_test, y_pred)\n",
    "    rec = metrics.recall_score(y_test, y_pred) # it is also called detection rate or true positive rate\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    print(f\"Acc {acc}, Precision {pre}, Recall {rec}, F1-score {f1}\")\n",
    "    \n",
    "    CM = metrics.confusion_matrix(y_test, y_pred)\n",
    "    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n",
    "    # false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # false alarm rate \n",
    "    FAR = (FP+FN)/(TP+TN+FP+FN)\n",
    "    AUC = metrics.roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    print(\"FPR {0}, FAR {1}, AUC {2}\".format(FPR, FAR, AUC))\n",
    "    # print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "def test_run(x_train, y_train, x_test, y_test, param, num_round=2000):\n",
    "    start = time.clock()\n",
    "    \n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_validation = lgb.Dataset(x_test, y_test)\n",
    "    clf = lgb.train(param, lgb_train, num_round, valid_sets=[lgb_validation], early_stopping_rounds=50, verbose_eval=200, feval=lgb_f1_score)\n",
    "    # clf = lgb.train(param, lgb_train, 2000, valid_sets=[lgb_validation], early_stopping_rounds=50, verbose_eval=200)\n",
    "    y_prob = clf.predict(x_test, num_iteration=clf.best_iteration)\n",
    "    \n",
    "    print()\n",
    "    results(y_test, y_prob)\n",
    "    print(\"Time spent {0}\".format(time.clock() - start))\n",
    "    return y_prob\n",
    "    \n",
    "def cross_validation(X, Y, param, kf, num_round=2000):\n",
    "    start = time.clock()\n",
    "    y_probs = []\n",
    "    y_vals = []\n",
    "\n",
    "    # for tr_idx, val_idx in tqdm(kf.split(X, Y), total=folds):\n",
    "    for tr_idx, val_idx in kf.split(X, Y):\n",
    "        clf = run_lgb(X, Y, tr_idx, val_idx, param, num_round)\n",
    "        x_val, y_val = X.iloc[val_idx], Y.iloc[val_idx]\n",
    "        y_prob = clf.predict(x_val, num_iteration=clf.best_iteration)\n",
    "        \n",
    "        y_probs.extend(y_prob)\n",
    "        y_vals.extend(y_val)\n",
    "\n",
    "    print()\n",
    "    results(y_vals, np.asarray(y_probs))\n",
    "    print(\"Time spent {0}\".format(time.clock() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test sets are reversed here. Fixing them.\n",
      "Dropping attack_cat\n",
      "Dropping id\n",
      "Dropping attack_cat\n",
      "Dropping id\n"
     ]
    }
   ],
   "source": [
    "train, test = input_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def lgb_accuracy(preds, data):\n",
    "    y_true = data.get_label()\n",
    "    y_pred = np.round(preds)\n",
    "    return 'acc', metrics.accuracy_score(y_true, y_pred), True\n",
    "\n",
    "def lgb_f1_score(preds, data):\n",
    "    y_true = data.get_label()\n",
    "    y_pred = np.round(preds) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', metrics.f1_score(y_true, y_pred), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column mismatch set(), set()\n",
      "Number of features 54\n",
      "Time spent in total preprocessing 4.759016 s\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "seed = 1\n",
    "num_round = 2000\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "start = time.clock() \n",
    "drop_columns = ['is_sm_ips_ports', 'dwin', 'is_ftp_login', 'trans_depth', 'dttl', 'ct_ftp_cmd']\n",
    "for df in [train, test]:\n",
    "    df.drop(drop_columns, axis=1, inplace=True)\n",
    "x_train, y_train, x_test, y_test = get_train_test(train, test, feature_engineer=True, label_encoding=False, scaler=StandardScaler())\n",
    "print(\"Time spent in total preprocessing {0} s\".format(time.clock() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0776548\n",
      "[400]\tvalid_0's binary_logloss: 0.0636346\n",
      "[600]\tvalid_0's binary_logloss: 0.0536225\n",
      "[800]\tvalid_0's binary_logloss: 0.0459373\n",
      "[1000]\tvalid_0's binary_logloss: 0.0396676\n",
      "[1200]\tvalid_0's binary_logloss: 0.0345212\n",
      "[1400]\tvalid_0's binary_logloss: 0.0303571\n",
      "[1600]\tvalid_0's binary_logloss: 0.026872\n",
      "[1800]\tvalid_0's binary_logloss: 0.0237827\n",
      "[2000]\tvalid_0's binary_logloss: 0.0211797\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's binary_logloss: 0.0211797\n",
      "\n",
      "Acc 0.9961161394083529, Precision 0.9953495750329788, Recall 0.998960960608676, F1-score 0.9971519979925977\n",
      "FPR 0.009946428571428571, FAR 0.0038838605916471335, AUC 0.999927484806443\n",
      "Time spent 268.59143\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective': 'binary', \n",
    "    'learning_rate': 0.1, \n",
    "    \"boost_from_average\":True,\n",
    "    \"metric\": 'binary_logloss' # 'auc'\n",
    "}\n",
    "start = time.clock()\n",
    "# test_run( x_train, y_train, x_train, y_train, param)\n",
    "clf = lgb.train(param, lgb.Dataset(x_train, y_train), 2000, valid_sets=[lgb.Dataset(x_train, y_train)], early_stopping_rounds=50, verbose_eval=200)\n",
    "y_prob = clf.predict(x_train, num_iteration=clf.best_iteration)\n",
    "print()\n",
    "results(y_train, y_prob)\n",
    "print(\"Time spent {0}\".format(time.clock() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acc 0.8688116406743429, Precision 0.8191345816158666, Recall 0.9775875761051795, F1-score 0.8913740910965172\n",
      "FPR 0.2644594594594595, FAR 0.1311883593256571, AUC 0.9809944714192707\n"
     ]
    }
   ],
   "source": [
    "y_prob = clf.predict(x_test, num_iteration=clf.best_iteration)\n",
    "print()\n",
    "results(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ten-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping irrelevant columns, feature engineering and applying oneHotEncoding. We found among different scaling StandardScaler is performing the best.\n",
    "\n",
    "|Preprocess| Param | Accuracy |F1-score |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|RobustScaler|learning rate 0.05|96.11| 97.16|\n",
    "||learning rate 0.1|95.19| 97.22|\n",
    "||learning rate 0.3|95.73| 96.88|\n",
    "|StandardScaler |learning rate 0.05|96.08| 97.14 |\n",
    "||learning rate 0.1| 96.20 | 97.23|\n",
    "||learning rate 0.3| 95.71 | 96.87|\n",
    "|MinMaxScaler |learning rate 0.05|96.08| 97.14\n",
    "| |learning rate 0.1|96.20|97.22 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.0929967\tvalid_0's f1: 0.96977\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0870685\tvalid_0's f1: 0.970869\n",
      "[400]\tvalid_0's binary_logloss: 0.0819235\tvalid_0's f1: 0.972575\n",
      "Early stopping, best iteration is:\n",
      "[361]\tvalid_0's binary_logloss: 0.0825926\tvalid_0's f1: 0.972861\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0928118\tvalid_0's f1: 0.969198\n",
      "[400]\tvalid_0's binary_logloss: 0.088741\tvalid_0's f1: 0.970967\n",
      "Early stopping, best iteration is:\n",
      "[436]\tvalid_0's binary_logloss: 0.0883625\tvalid_0's f1: 0.971624\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0882203\tvalid_0's f1: 0.970273\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's binary_logloss: 0.0878964\tvalid_0's f1: 0.970211\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0851422\tvalid_0's f1: 0.971214\n",
      "[400]\tvalid_0's binary_logloss: 0.0809647\tvalid_0's f1: 0.972698\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid_0's binary_logloss: 0.0807477\tvalid_0's f1: 0.973063\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0903474\tvalid_0's f1: 0.970186\n",
      "[400]\tvalid_0's binary_logloss: 0.0856771\tvalid_0's f1: 0.972218\n",
      "[600]\tvalid_0's binary_logloss: 0.0836037\tvalid_0's f1: 0.973\n",
      "Early stopping, best iteration is:\n",
      "[564]\tvalid_0's binary_logloss: 0.0836913\tvalid_0's f1: 0.973333\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0904898\tvalid_0's f1: 0.971112\n",
      "[400]\tvalid_0's binary_logloss: 0.0855424\tvalid_0's f1: 0.972937\n",
      "Early stopping, best iteration is:\n",
      "[465]\tvalid_0's binary_logloss: 0.0847514\tvalid_0's f1: 0.973185\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0896449\tvalid_0's f1: 0.970367\n",
      "[400]\tvalid_0's binary_logloss: 0.0861096\tvalid_0's f1: 0.971823\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's binary_logloss: 0.0855655\tvalid_0's f1: 0.972362\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0888363\tvalid_0's f1: 0.971068\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's binary_logloss: 0.0863381\tvalid_0's f1: 0.972495\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0887736\tvalid_0's f1: 0.970226\n",
      "[400]\tvalid_0's binary_logloss: 0.0854331\tvalid_0's f1: 0.971702\n",
      "Early stopping, best iteration is:\n",
      "[486]\tvalid_0's binary_logloss: 0.0847988\tvalid_0's f1: 0.972516\n",
      "\n",
      "Acc 0.961811555768474, Precision 0.9654252022509978, Recall 0.9789510729757586, F1-score 0.9721410918894631\n",
      "FPR 0.07471428571428572, FAR 0.038188444231525995, AUC 0.994479891355743\n",
      "Time spent 628.102498\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective': 'binary', \n",
    "    'learning_rate': 0.1, \n",
    "    \"boost_from_average\":True,\n",
    "    \"metric\": 'binary_logloss' # 'auc'\n",
    "}\n",
    "cross_validation(x_train, y_train, param, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0891891\tvalid_0's f1: 0.969969\n",
      "[400]\tvalid_0's binary_logloss: 0.0850312\tvalid_0's f1: 0.971909\n",
      "Early stopping, best iteration is:\n",
      "[455]\tvalid_0's binary_logloss: 0.0845862\tvalid_0's f1: 0.972279\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0918073\tvalid_0's f1: 0.969483\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's binary_logloss: 0.0887961\tvalid_0's f1: 0.970875\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.089209\tvalid_0's f1: 0.970017\n",
      "[400]\tvalid_0's binary_logloss: 0.0848384\tvalid_0's f1: 0.972391\n",
      "Early stopping, best iteration is:\n",
      "[391]\tvalid_0's binary_logloss: 0.0849441\tvalid_0's f1: 0.972494\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0905414\tvalid_0's f1: 0.9708\n",
      "[400]\tvalid_0's binary_logloss: 0.0864308\tvalid_0's f1: 0.97204\n",
      "Early stopping, best iteration is:\n",
      "[367]\tvalid_0's binary_logloss: 0.0866538\tvalid_0's f1: 0.972082\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0899727\tvalid_0's f1: 0.970367\n",
      "[400]\tvalid_0's binary_logloss: 0.0859435\tvalid_0's f1: 0.972329\n",
      "Early stopping, best iteration is:\n",
      "[532]\tvalid_0's binary_logloss: 0.0849463\tvalid_0's f1: 0.97282\n",
      "\n",
      "Acc 0.9617773367324243, Precision 0.9656004828002414, Recall 0.9787080718277876, F1-score 0.9721100947973799\n",
      "FPR 0.07430357142857143, FAR 0.03822266326757575, AUC 0.9944317694972509\n",
      "Time spent 414.5320310000001\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cross_validation(x_train, y_train, param, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0361828\tvalid_0's f1: 0.988951\n",
      "[400]\tvalid_0's binary_logloss: 0.0203956\tvalid_0's f1: 0.995678\n",
      "[600]\tvalid_0's binary_logloss: 0.0123723\tvalid_0's f1: 0.99861\n",
      "[800]\tvalid_0's binary_logloss: 0.00774753\tvalid_0's f1: 0.999382\n",
      "[1000]\tvalid_0's binary_logloss: 0.00493171\tvalid_0's f1: 0.999614\n",
      "[1200]\tvalid_0's binary_logloss: 0.0031983\tvalid_0's f1: 0.99979\n",
      "Early stopping, best iteration is:\n",
      "[1236]\tvalid_0's binary_logloss: 0.00294144\tvalid_0's f1: 0.999801\n",
      "\n",
      "Acc 0.9997813729777001, Precision 0.9997132774591971, Recall 0.9998897026383129, F1-score 0.999801482265749\n",
      "FPR 0.00035135135135135135, FAR 0.00021862702229995628, AUC 0.99999988105771\n",
      "Time spent 249.51189699999986\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective': 'binary', \n",
    "    'learning_rate': 0.1, \n",
    "    \"boost_from_average\":True,\n",
    "    \"metric\": 'binary_logloss' # 'auc'\n",
    "}\n",
    "y_prob = test_run(x_test, y_test, x_test, y_test, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate on test data\n",
    "Here the model trained on test data is being validated using test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Param|Accuracy|F1-score|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|learning_rate 0.1 | 87.74 | 89.87\n",
    "|learning_rate 0.05 | 87.60 | 89.77\n",
    "|learning_rate 0.1, is_unbalance True | 91.87 | 92.9\n",
    "|learning_rate 0.05, is_unbalance True | 91.95 | 92.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.1853\tvalid_0's f1: 0.929638\n",
      "\n",
      "Acc 0.9194845260651995, Precision 0.8958900186166404, Recall 0.9660284126003706, F1-score 0.9296381603388068\n",
      "FPR 0.13754054054054055, FAR 0.08051547393480056, AUC 0.9864868024735227\n",
      "Time spent 37.99111300000004\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.05, \n",
    "    'boost_from_average':True,\n",
    "    'is_unbalance':True,\n",
    "    \"metric\": 'binary_logloss' # 'auc'\n",
    "}\n",
    "y_prob = test_run(x_train, y_train, x_test, y_test, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31911  5089]\n",
      " [ 1540 43792]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = np.where(y_prob >= 0.5, 1, 0)\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Normal', 'Anomaly']\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "# Normalize\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.rc('font', size=20) \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=target_names, yticklabels=target_names)\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    " \n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ten-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Param|Accuracy| F1-score|\n",
    "|:---:|:---:|:---:|\n",
    "|learning_rate 0.05| 98.07 | 98.24\n",
    "|learning_rate 0.1| 98.18 | 98.34\n",
    "|learning_rate 0.3| 98.08 | 98.25\n",
    "|learning_rate 0.1, feature_fraction 0.5 | 98.14 | 98.30\n",
    "|learning_rate 0.05, feature_fraction 0.5| 98.04 | 98.21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0482127\tvalid_0's f1: 0.983017\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's binary_logloss: 0.0459499\tvalid_0's f1: 0.985022\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0568795\tvalid_0's f1: 0.980466\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's binary_logloss: 0.0544355\tvalid_0's f1: 0.982016\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0522023\tvalid_0's f1: 0.981842\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's binary_logloss: 0.0514076\tvalid_0's f1: 0.982953\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0516532\tvalid_0's f1: 0.982339\n",
      "Early stopping, best iteration is:\n",
      "[333]\tvalid_0's binary_logloss: 0.0477933\tvalid_0's f1: 0.984906\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.050421\tvalid_0's f1: 0.982728\n",
      "[400]\tvalid_0's binary_logloss: 0.0471405\tvalid_0's f1: 0.985507\n",
      "Early stopping, best iteration is:\n",
      "[395]\tvalid_0's binary_logloss: 0.0471604\tvalid_0's f1: 0.985616\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0523314\tvalid_0's f1: 0.981592\n",
      "[400]\tvalid_0's binary_logloss: 0.0484329\tvalid_0's f1: 0.983392\n",
      "Early stopping, best iteration is:\n",
      "[416]\tvalid_0's binary_logloss: 0.0483049\tvalid_0's f1: 0.983498\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0579025\tvalid_0's f1: 0.979727\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.0592219\tvalid_0's f1: 0.980162\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0516403\tvalid_0's f1: 0.983577\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's binary_logloss: 0.0502346\tvalid_0's f1: 0.983817\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0522372\tvalid_0's f1: 0.9829\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's binary_logloss: 0.0496223\tvalid_0's f1: 0.984462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0571176\tvalid_0's f1: 0.980632\n",
      "[400]\tvalid_0's binary_logloss: 0.0535907\tvalid_0's f1: 0.981984\n",
      "Early stopping, best iteration is:\n",
      "[398]\tvalid_0's binary_logloss: 0.0535503\tvalid_0's f1: 0.981871\n",
      "\n",
      "Acc 0.9818539571491036, Precision 0.9887615394907016, Recall 0.9781611223859525, F1-score 0.9834327663066379\n",
      "FPR 0.013621621621621621, FAR 0.018146042850896372, AUC 0.9982527279220454\n",
      "Time spent 281.1151239999999\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.1, \n",
    "    \"boost_from_average\":True,\n",
    "    # 'is_unbalance':True,\n",
    "    # \"feature_fraction\":0.5,\n",
    "    \"metric\": 'binary_logloss' # 'auc'\n",
    "}\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cross_validation(x_test, y_test, param, kf, num_round=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0535638\tvalid_0's f1: 0.981693\n",
      "[400]\tvalid_0's binary_logloss: 0.0493049\tvalid_0's f1: 0.983088\n",
      "Early stopping, best iteration is:\n",
      "[360]\tvalid_0's binary_logloss: 0.0495075\tvalid_0's f1: 0.983421\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0533186\tvalid_0's f1: 0.982038\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's binary_logloss: 0.0515242\tvalid_0's f1: 0.983376\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0513647\tvalid_0's f1: 0.982215\n",
      "[400]\tvalid_0's binary_logloss: 0.0470931\tvalid_0's f1: 0.983674\n",
      "Early stopping, best iteration is:\n",
      "[388]\tvalid_0's binary_logloss: 0.0471132\tvalid_0's f1: 0.983784\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.0583507\tvalid_0's f1: 0.980977\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.0564075\tvalid_0's f1: 0.980427\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's binary_logloss: 0.0580155\tvalid_0's f1: 0.980649\n",
      "\n",
      "Acc 0.9807729679832872, Precision 0.9879106907858051, Recall 0.977036089296744, F1-score 0.9824432983973825\n",
      "FPR 0.014648648648648649, FAR 0.01922703201671282, AUC 0.9981241217945201\n",
      "Time spent 155.66113700000028\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cross_validation(x_test, y_test, param, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined data\n",
    "Here we combined both train and test set. Then evaluated their ten-fold cross validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([train, test], axis=0)\n",
    "X, Y = total.drop(['label'], axis=1), total['label']\n",
    "categorical_columns = get_cat_columns(X)\n",
    "non_categorical_columns = [col for col in X.columns if col not in categorical_columns]\n",
    "X = feature_process(X)\n",
    "X[non_categorical_columns] = StandardScaler().fit_transform(X[non_categorical_columns])\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Param | Accuracy | F1-score\n",
    "|:---:|:---:|:---:|\n",
    "|learning rate 0.05 | 95.11 | 96.15\n",
    "|learning rate 0.01 | 93.69 | 95.07\n",
    "|learning rate 0.1 | 95.09 | 96.07\n",
    "|learning rate 0.1, is_unbalance True | 95.16 | 96.19\n",
    "|learning rate 0.1, bagging_fraction 0.8 | 95.14 | 96.17\n",
    "|learning rate 0.1, feature_fraction 0.5 | 95.20 | 96.22\n",
    "|learning rate 0.1, feature_fraction 0.5, bagging_fraction 0.8 | 95.05 | 96.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.108583\tvalid_0's f1: 0.958986\n",
      "[400]\tvalid_0's binary_logloss: 0.104327\tvalid_0's f1: 0.961015\n",
      "Early stopping, best iteration is:\n",
      "[400]\tvalid_0's binary_logloss: 0.104327\tvalid_0's f1: 0.961015\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.108378\tvalid_0's f1: 0.95867\n",
      "[400]\tvalid_0's binary_logloss: 0.104467\tvalid_0's f1: 0.961183\n",
      "[600]\tvalid_0's binary_logloss: 0.102306\tvalid_0's f1: 0.962104\n",
      "[800]\tvalid_0's binary_logloss: 0.100991\tvalid_0's f1: 0.962723\n",
      "Early stopping, best iteration is:\n",
      "[901]\tvalid_0's binary_logloss: 0.100696\tvalid_0's f1: 0.963265\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.109639\tvalid_0's f1: 0.958035\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's binary_logloss: 0.106194\tvalid_0's f1: 0.960779\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.108464\tvalid_0's f1: 0.958849\n",
      "[400]\tvalid_0's binary_logloss: 0.10384\tvalid_0's f1: 0.961198\n",
      "Early stopping, best iteration is:\n",
      "[422]\tvalid_0's binary_logloss: 0.103588\tvalid_0's f1: 0.961484\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.109992\tvalid_0's f1: 0.957926\n",
      "[400]\tvalid_0's binary_logloss: 0.105855\tvalid_0's f1: 0.96004\n",
      "Early stopping, best iteration is:\n",
      "[524]\tvalid_0's binary_logloss: 0.104735\tvalid_0's f1: 0.960835\n",
      "\n",
      "Acc 0.9510814093832105, Precision 0.9678209293167946, Recall 0.9552142731352438, F1-score 0.9614762791067264\n",
      "FPR 0.056236559139784946, FAR 0.0489185906167895, AUC 0.9924826274802411\n",
      "Time spent 519.276269\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.1, \n",
    "    \"boost_from_average\":True,\n",
    "    # 'is_unbalance':True,\n",
    "    # \"bagging_fraction\":0.8,\n",
    "    \"feature_fraction\":0.5,\n",
    "    # \"bagging_freq\":1,\n",
    "    \"metric\": 'binary_logloss' # 'auc'\n",
    "}\n",
    "cross_validation(X, Y, param, kf, num_round=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
